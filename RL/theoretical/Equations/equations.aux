\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Finite Markov Decision Processes}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Value and State-Value Functions}}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Bellman Optimality Equations}}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dynamic Programming}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Policy Iteration}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Value Iteration}}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Monte Carlo Methods}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces First-visit MC Prediction}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Exploring Start MC Control}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces On-policy first-visit MC Control}}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Off-policy MC Prediction}}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Off-policy MC Control}}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Temporal-Difference Learning}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces One step TD}}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces SARSA Diagram}}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces SARSA: On-policy TD Control}}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Q-learning: Off-policy TD Control}}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {5}$n$-step Bootstrapping}{12}}
